{"Abstract-Data-Type-(ADT)":{"title":"Abstract Data Type (ADT)","links":["classes/EECS-281","Data-Structure"],"tags":["eecs-281"],"content":"Relevant Classes: EECS 281\nAn abstract data type (ADT) combines data with valid operations and their behaviors on stored data.\nThink of an ADT Like a “black box” with a bunch of buttons. Each button does an action (e.g. “delete,” “insert,” etc) but the implementation details about how that action is done “under-the-hood” isn’t explained. It’s an interface that describes what something needs to do, but doesn’t describe how it is supposed to do it.\nOn the other hand, a Data Structure is the implementation of an Abstract Data Type."},"Big-O-Notation":{"title":"Big-O Notation","links":["classes/EECS-281","classes/EECS-376","Big-Theta","Big-Omega"],"tags":["eecs-281","eecs-376"],"content":"Relevant Classes: EECS 281, EECS 376\nThe Asymptotic Upper Bound for a function in the following regard:\nf(n)=O(g(n))⟺∃c&gt;0∧n0​≥0 s.t. ∀n≥n0​,f(n)≤c⋅g(n)\nA sufficient (but not necessary) condition:\nIf limn→∞​(g(n)f(n)​)=d&lt;∞, then f(n) is O(g(n)).\n\nNote: Since this is just a sufficient (but not necessary) condition, if the limit is not a non-infinite constant, that does not mean that f(n)=O(g(n)).\n\nThis is similar to and related to: Big-Theta and Big-Omega"},"Big-Omega":{"title":"Big-Omega","links":["classes/EECS-281","classes/EECS-376"],"tags":["eecs-281","eecs-376"],"content":"Relevant Classes: EECS 281, EECS 376\nThe Asymptotic Lower Bound."},"Caller-Save-vs-Callee-Save":{"title":"Caller Save vs Callee Save","links":["classes/EECS-370"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nWhen calling a function, the currently stored register values have to be saved at some step in the process—at least the ones whose values are going to be used after the function call is over. There are two ways this saving can be implemented: it can be caller-save, or callee-save.\nWhen considering all possible programs, these roughly equate to the same performance / situation, so the only thing that’s really important in the end is consistency.\nCaller Save\nWhen using the caller-save paradigm, this means that each function itself is responsible for saving all relevant registers before calling any function (onto its stack) and then retrieving them once the task is done.\nThere are a few key advantages to this. Primarily, the calling function knows which values it still needs to use after the function is done, so it knows which values don’t need to be saved.\nCallee Save\nThe callee-save paradigm is the opposite idea. Each function, before running or executing, assumes that the place that it was called from didn’t save any registers. This means that the function will need to save and restore all the registers that it plans on using at the start and end of the function.\nAgain, the key advantage here is that only the registers that the function is planning on using end up needing to be saved on the stack: the rest can simply be ignored because they’re not changed.\nCombining Both\nWhat a lot of Modern ISAs do, then, is to have some registers be caller-saved registers and others be callee-saved registers. This way, the compiler can assign variables to the most optimal register to minimize stack accesses. For example, a variable that is only used before a function call would be added to a caller-save register if possible, so that by the time the function is called, you don’t need to access the stack to save said value (since it wasn’t relevant after the function call anyways)."},"Combinational-Logic":{"title":"Combinational Logic","links":["classes/EECS-370","Full-Adder-Circuit","Ripple-Carry-Adder"],"tags":["eecs-370"],"content":"Relevant Class: EECS 370\nCombinational Logic allows us to do things with the binary that we have created.\nTransistors\nTransistors can essentially be viewed as an electronic switch. High Voltage turns the transistor on, while a low voltage can turn it off (on means it acts like a wire, off means it acts like there’s a break)\nLogic Gates\nLogic Gates are an essential way for us to represent how we handle and deal with the data we’re given (they all also have hardware counterparts). For example, if we want to do an and command, there is a logic gate that we can implement to do that at the bit level, which we can extend to larger binary numbers.\nInverter\nThe inverter is a really basic logic gate that simply takes in an input bit and inverts it.\nHere is its Truth Table:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInputOutput1001\nAND and OR Gate\nIt’s an AND and OR gate…\nNAND Gate\nConceptually, a NAND gate is simply an AND gate with an inverter afterwards.\nXOR (eXclusive OR)\nLike an OR gate, but both can’t be true at the same time.\nXNOR Gate\nSimply an Inverted XOR Gate (requires the two bits to be equal)\nMuxes\nA mux, also known as a Multiplexer, allows us to take many inputs and choose a single output.\nMuxes can be built from Logic Gates.\nDecoder\nIt takes an N-bit binary number and spits out 2N bits, exactly one of which will be high (essentially spitting out 2i where i is an N-bit binary number).\nThese allow us to index into things, like a register file.\nAdders\nIt takes in two binary numbers an adds them together. The most common implementation of this is a chain of Full-Adder Circuits, and one such example of this chain is called a Ripple Carry Adder. Note: a Ripple Carry Adder is not the most efficient and not used often in hardware because you have to wait for each calculation to propagate through all the Full-Adder Circuits; however, it is a good example to look at even though it is not used in practice.\nSubtraction\nRecall that A - B = A + (-B) = A + (~B + 1), so we can just add 1 to the original carry bit, negate B, and end up able to use the same circuit logic to perform our addition.\nArithmetic-Logic Units (ALUs)\nThe basic ALU for LC2K is a simple Logical Unit that combines a 32-bit NOR Gate and a Ripple Carry Adder, with a selection bit to allow choosing between the two.\nPropagation Delay\nWhile we often act like, as soon as a gate’s input change, the gate’s output changes. However, that is not exactly true (for various reasons, like electrons, speed of light, transistors requiring a build-up of electrons, etc). For simplicity, we’ll just consider the result: a delay between when inputs change and when an output actually ends up reacting to the change in inputs. This delay is called the Propagation Delay.\nWhen considering a circuit that has multiple possible data paths, we refer to the delay of the circuit being the delay of the longest data path. This is because generally, based on the inputs, all data paths could be taken, so we need to be able to accommodate all possible flows of information (we will ignore the case of a circuit having a useless datapath whose value is never used, because the answer then depends on the person who is asking the question)."},"Complexity-Analysis":{"title":"Complexity Analysis","links":["classes/EECS-281","classes/EECS-376","Big-O-Notation"],"tags":["eecs-281"],"content":"Relevant Classes: EECS 281, EECS 376\nAt it’s core, it attempts to answer the question: Given an algorithm and input size n, how many steps are needed?\nThe major metrics that are used are:\n\nBest Case\nWorst Case\nAverage Case\n\nNotation and Terminology:\n\nn: Input Size\nf(n): Maximum number of steps taken by an algorithm when input has size n\nO(f(n)): Complexity class of f(n). (Big-O Notation)\n"},"Deque":{"title":"Deque","links":["classes/EECS-281","Queue","Stack","Vector","Circular-Buffer","Doubly-Linked-List"],"tags":["eecs-281","data-structure"],"content":"Relevant Classes: EECS 281\nA Deque is a “Double-Ended Queue,” but is essentially a Data Structure that supports both Queue-like and Stack-like behavior.\nIt has six major methods to support these behaviors:\n\npush_front(object)\npop_front()\nobject&amp; front()\npush_back(object)\npop_back()\nobject&amp; back()\n\nUniquely, you can traverse the stl::deque with an iterator and it allows random access of elements in constant time (though slower than a Vector)\nImplementations:\n\nCircular Buffer\nDoubly-Linked List\n"},"Finite-State-Machine-(FSM)":{"title":"Finite State Machine (FSM)","links":["classes/EECS-370","Sequential-Logic","Read-Only-Memory-(ROM)","Combinational-Logic"],"tags":["eecs-370"],"content":"Relevant Classes: EECS 370\nA finite state machine is exactly what it sounds like: a state machine with a finite number of states, with multiple inputs that change what the next state is and the output is.‘\nGenerally, to store the current state, an FSM uses D Flip-FlopsROM]] to determine the transition function (output to the next state).\nThere are two types of FSMs: Moore Machines and Mealy Machines. These terms help describe what the output is based on.\nMoore Machines\nIn Moore Machines, the output of the Machine is solely dependent on the current state. These are often associated with more states, because based on the input, you might need to have a different output. Therefore, instead of having one state with the output depending on how you got to that state, you have a different state for each path to the next state.\nMealy Machines\nMealy machines are the opposite: their output is dependent on the current state, and the last input. Contrarily to Moore Machines, the input at a certain point, plus the current state, can determine what the output would be. This often leads to slightly more complicated circuits, but fewer states.\nImplementing an FSM using ROM\nDesigning a custom circuit can be done using gates, but that can get very financially straining (especially for something small). The alternative is to use memory:\n\nThe entire program can be seen as a very large truth table: the current state, input bits, and then the output / next state.\nWith this in mind, we can literally just store all the possible combinations of states and inputs in memory and “index” into it—which would be cheaper and more efficient. These tables are called, Read Only Memory, or ROMs.\n\nBasic Limitations\nLet’s do some math here. If we recall how to calculate ROM sizes, n input bits and y output bits gives us a size of 2n⋅y, which grows exponentially with regard to the input size. This means that each additional input state, the size requirement doubles, which can become very costly. Therefore, there comes a point where—if the number of inputs is large enough—a ROM might not be the best option, and instead you can use Combinational Logic.\nOptimizations\nOften, the optimizations involve reducing the number of input bits, and then doing some post-processing using combination logic (essentially combining memory with combinational logic). This is because combinational logic does not grow exponentially with input size, and thus can reduce our complexity by a very large margin."},"Floating-Point-Numbers":{"title":"Floating Point Numbers","links":["classes/EECS-370","Biased-Numbers-(Floating-Point-Exponents)"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nFloating Point Numbers are a way to represent non-integer rational numbers using binary. It takes some inspiration from scientific notation, essentially representing a number using the following form:\nx⋅2y.\nThis allows us to represent a huge range of numbers using very compact notation.\nThe relevant floating point format is the IEEE 7544? Floating Point Format.\nFloating Point Format\nThere are three parts:\n\nSign Bit: 0 is positive, 1 is negative\nSignificant (aka the mantissa): Stores the 23 most significant bits after the decimal point\nExponent: Used a Biased Base 127 Encoding (store the number + 127)\n\nWe can represent any number from [-127, 128]\n\n\n\nZero is simply represented as having all zeros for the exponent bits.\nThe first bit is the Sign Bit\nThe next eight bits are the exponent bits.\nThe last 23 bits are the mantissa.\nSince we have already decided the zero case, you’ll realize that all numbers (since they’re in scientific notation) will start with 1.XXX..., or a 1 before the decimal point. Since this is true, to save space we remove this redundant information and just assume the one is there. This let’s us technically have an extra bit of information to store, which is neat."},"Generating-Unique-Identifiers":{"title":"Generating Unique Identifiers","links":["classes/EECS-482","Mutex","Process-ID-(PID)","Thread"],"tags":["eecs-482"],"content":"Relevant Classes: EECS 482\nWhen implementing a thread library, one of the challenges is to be able to generate a unique identifier for every thread (additionally used to link it with its mutexes).\nWhy Not PIDs\nUsually, a computer uses a Process ID (PID) for this: however, PIDs are not actually unique:\n\nthey’re based off of your computer’s unix timestamp, which can be user-manipulated\nthey contain stochastic bits, which are also not guaranteed to be unique\n\nIn most cases, the probability of duplication is so low that this is a non-issue. However, in this class, we can’t use that assumption—you will actually be tested on cases like these.\nFirst Idea: Incrementing ID Number\nThe most common idea that people come up with first is something simple like the following: an incrementing UID type. Simply increment the ID every time a new process is created.\nclass Uid {\n\tstatic const uint64_t get_uid() {\n\t\tstatic std::atomic&lt;uint64_t&gt; id(0);\n\t\treturn id++;\n\t}\n}\nThat’s awesome! Now, with the Uid class, we can generate incrementing ID’s! This seems to work great, until…\n// EECS482 Test Case\nstd::vector&lt;uint64_t&gt; random_ids;\nstd::mt19937 rng(std::random_device{}());\nstd::uniform_int_distribution&lt;&gt; distribution(1, 10);\n \nfor (uint64_t i = 0; i &lt; std::numeric_limits&lt;uint64_t&gt;::max(); i++) {\n\tfor (uint128_t j = 0; j &lt; std::numeric_limits&lt;uint64_t&gt;::max(); j++) {\n\t\tauto id = Uid::get_id();\n\t\tif (distribution(rng) &lt;= 5) random_ids.push_back(id);\n\t}\n}\nIn the following case, we end up in a situation where it is possible to potentially have duplicate ID values. Now, while this situation is really really unlikely (and not really something that you can expect to encounter), if a program runs for long enough, and each process lasts an indefinite amount of time, over a long enough period of time, you will encounter issues. This won’t work.\nWe need to use an important idea of this problem: IDs can be recycled. On other words, once something using the ID goes “out of scope,” we can reuse the ID—but in any other situation, we can’t.\nSolution: Get Someone Else to do the Work\nNo, literally. You can spend all the time in the world thinking about the best way to come up with an algorithm that can come up with a unique 64-bit unsigned integer value to represent a process, but you’re most likely not going to make much headway. If you do, there’s a good chance you’re actually using the same algorithm under the hood that the actual solution uses.\nLet’s frame the problem in a different way: we have a “pool” of possible values, and we can “allocate” and “deallocate” each value (once we finish using it). We want to make sure we can always get a unique value from the pool of currently unallocated values.\nDoes this ring a bell? This is actually the same idea that your operating system uses when deciding how to allocate memory on the heap! We can use that to our advantage. On a 64-bit system, each allocation has a 64-bit memory address, so we can actually allocate a physical byte and use its address as the ID. Once our process ends, we can simply delete the chunk of memory and free it up again to be picked up.\nHere’s a basic idea (influenced by this stackoverflow post).\ntemplate &lt;typename bitsize_t = uint64_t&gt;\nclass Uid&lt;bitsize_t&gt; {\n  public:\n\tstatic const bitsize_t reserve_id() {\n\t\tuint8_t id_byte = new uint8_t; // we could also use a char\n\t\t*id_byte = 0x42;\n\t\t// Note: this code is untested and I have no idea if the\n\t\t//       cast works correctly\n\t\treturn reinterpret_cast&lt;bitsize_t&gt;(id_byte);\n\t}\n \n\tstatic void recycle_id(bitsize_t id) {\n\t\t// Note: this code is untested and I have no idea if the\n\t\t//       cast works correctly\n\t\tuint8_t* id_byte = static_cast&lt;uint8_t*&gt;(id);\n\t\tif (*id_byte == 0x42) {\n\t\t\t*id_byte = 0;\n\t\t\tdelete id_byte;\n\t\t}\n\t}\n}\nNow, you might notice a small issue with this: what if we have two things using the id to show they’re linked processes? Namely, a Mutex and a Thread? Either can go out of scope and be deleted before the other, so how do we know when to delete?\nOne idea is that we can always delete it when the actual value goes out of scope—that’s what’s important, right? Not quite. We have to remember that we are trying to use a computer concurrently. As soon as the value goes out of scope, its address is now available for use again! That means that, in the gap between a value being destructed and its mutex being destructed, the computer could reuse the address and set it as “allocated” again.\nThe way to fix this (to essentially lock the memory space so long as either the thread or the mutex is alive) is actually really simple. We won’t be able to use a raw uint64_t to store the address, but we will need to create some sort of container to wrap it. Think something reference counted."},"Instruction-Set-Architecture-(ISA)":{"title":"Instruction Set Architecture (ISA)","links":["classes/EECS-370","Registers","Program-Counter","Pointer","Struct","LEGv8","LC2K"],"tags":["eecs-370"],"content":"Relevant Classes: EECS 370\nISAs are a is a description of what operations that a specific set of hardware will support and understand. They are platform-specific and intrinsically tied to what the hardware that it is created for.\nGenerally, ISAs use and depend on the following:\n\nRegisters\n\nControl Flow\nIn an assembly program, you almost go line by line. There is the notion of a Program Counter, or PC, that represents the current instruction that is being executed.\nAfter most instructions, the PC is incremented, but based on the ISA, there are generally a few instructions that can change the PC in different ways (think function calls, branching, etc).\nLoad-Store Architecture\n\nLoad data from memory into a register\nCalculate things based on stored register values (compact and fast)\nStore data back into memory from registers after they are done being used / calculated\n\nAddressing Modes\nDirect Addressing\nEquivalent to “hard-coding” the address in the instruction. However, if the instruction is the same size of the address, you can’t include both an address and the instruction you want to operate on that address, so it is impractical.\nRegister Indirect\nStore the address in a register, and use the register to access memory addresses (essentially storing an address in a variable, like a Pointer).\nBase + Displacement\nEssentially, it is a combination of the above two. For example, when using a structStructs]].\nPC-relative Addressing\nThis is the same as Base + Displacement, but uses the Program Counter as a base.\nExample ISAs\n\nLEGv8\nLC2K\n"},"LC2K-Multi-Cycle-Datapath":{"title":"LC2K Multi-Cycle Datapath","links":["classes/EECS-370","Instruction-Set-Architecture-(ISA)","LC2K","LC2K-Single-Cycle-Datapath","Program-Counter","Combinational-Logic","Read-Only-Memory-(ROM)"],"tags":["eecs-370"],"content":"Related Courses: EECS 370\nThe idea behind Multi-Cycle processors is that we can break instructions up into several steps, and then execute each step during a clock cycle. When doing this, now shorter instructions can take less time because they take fewer cycles.\nEspecially as ISAs become more complicated (think having a multiply opcode), this becomes a lot more valuable because you can have instructions that take many steps no longer holding back the performance of very simple instructions.\n\nNote: In LC2K, you’ll often notice that the performance benefit is not that large (or sometimes even negligible, if not negative). This is because all instructions are relatively tame and simple, so the overhead of a multi-cycle processor is often higher than the benefit that it offers.\n\n\nPrimary Changes from the LC2K Single-Cycle Datapath:\n\nEnabling / Disabling the Program Counter\nInstruction Register\n\nAllows us store the current instruction without having to call from memory\n\n\nMemory is Consolidated (Proper von Neumann Architecture)\n[[Combinational Logic#Arithmetic-Logic Units (ALUs)#ALUMux Now has 0 and 1 as options as well\nALU Result is stored\n\nCycles Per Instruction\nAll Instructions have the same first two cycles:\n\nCycle 0: Fetch Cycle\n\nThis involves reading from the instruction memory and storing the values fetched into the instruction register.\nDuring this cycle, we also calculate PC + 1 to use all parts of the processor because otherwise the ALU is not being used\n\n\nCycle 1: Decode\n\nThis involves taking the instruction from the instruction register and loading the relevant values from the Register file (regA, regB) / pass values into the Sign Extender\nDuring this cycle, we set PC to PC + 1\n\n\n\nAdd / Nor: 4 Cycles\n\nCycle 3: add/nor\n\nNow that we’ve read values from the register file, we can use the ALU to add/nor the values together and store the result in the ALU Result Register\n\n\nCycle 4: Store in Register File\n\nAfter we are sure that the ALU Result Register has updated, we can use this result as the input to the register file and store it into destReg\n\n\n\nLoad Word: 5 Cycles\n\nCycle 3: calculate regA + offset\n\nNow that we’ve read regA and sign-extended our destination, we can add those together to get the value in memory that we want to read to be able to store back into regB\n\n\nCycle 4: read regA + offset from memory (get MEM[regA + offset])\n\nUsing the ALU result, we can pass that as our source address for memory to read into the “data” register\n\n\nCycle 5: store MEM[regA + offset] into regB\n\nNow that the data from memory is calculated / stored in a register, we can store it into the register file at regB\n\n\n\nStore Word: 4 Cycles\n\nCycle 3: calculate regA + offset\n\nNow that we’ve read regA and sign-extended our destination, we can add those together to get the value in memory that we want to read to be able to store back into regB\nNote: we’re still going to want to read regB from the register file during this cycle, because that value will be used in the next cycle to write to memory\n\n\nCycle 4: write regB into MEM[regA + offset]\n\nUsing these calculated values, we can write our desired value into memory\n\n\n\nBEQ: 4 Cycles\n\nCycle 3: calculate beq destination (PC + 1 + offset)\n\nUsing the value of PC + 1 currently stored in PC already, we can add that to the sign extended offset using the ALU to get the potential next destination if the equality holds\n\n\nCycle 4: potentially update PC\n\nAdd an OR Gate to the PC-Enable bit: either the PC enable bit is 0, or we’re in State 12 (the state of this current cycle) AND the values in regA and regB are equal (changing the relevant muxes)\n\n\n\nChoosing Which State to Transition To\nTo avoid cluttering our ROMROM]] instead that takes in the opcode and calculates the next state.\nThis will require the use of an AND GateMux]].\nMeasuring Performance\nMeasuring performance of a multi-cycle datapath can be done using multiple (equivalent) formulas. Note: all of these depend on the specific distribution of instructions.\nThe first formula uses CPI, or “cycles-per instruction”. This is the average number of cycles per instruction in a program. The second can easily be obtained using dimensional analysis with the first. T=CPI⋅Icount​⋅Clock Period=Cycles⋅Clock Period, where T is total time and Icount​ is the number of instructions in the program total."},"LC2K-Single-Cycle-Datapath":{"title":"LC2K Single-Cycle Datapath","links":["classes/EECS-370","LC2K","Assembly","Sequential-Logic","Combinational-Logic","LC2K-Multi-Cycle-Datapath"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nNote: This is specific for the LC2KISA]] (if you recall, ISAs are intrinsically linked to Assembly, as well as the processor).\nA single-cycle datapath means that each LC2K instruction takes a single cycle through this circuitry to run—thus the name single-cycle.\n\nThere are three types of components:\n\nState: Everything in grey holds and represents state.\n\nFor now, we can assume that everything is stored using D Flip-Flops, even though they’re actually not the most efficient way to store large data like memory.\n\n\nCompute: Everything in blue is combinational logic to run computations.\n\nThis includes AddersALUs]], and more\n\n\nControl: Everything in orange isn’t transforming data per say, but controls the flow of information and logic through the circuitry\n\nThis primarily includes MuxesROM]]\n\n\n\nThe biggest drawback of single cycle processors like this one is that the clock period is limited by the slowest instruction (since the clock period is a constant). This means that, even if the slowest instruction is run the fewest time, it bottlenecks every instruction. Often, the effect of this can be fixed / negated by using Multi-Cycle Processors instead."},"LC2K":{"title":"LC2K","links":["classes/EECS-370","Assembly","Instruction-Set-Architecture-(ISA)","Program-Counter","Registers","Two's-Complement-Numbers"],"tags":["eecs-370"],"content":"Relevant Classes: EECS 370\nLC2K is a “fake” (albeit Turing Complete) Assembly Language designed by the EECS 370 staff to make learning the concepts of assembly easier (without the ridiculous number of opcodes and other functionality most real assembly languages have).\nInstructions are 32 bits in size, registers are 32 bits. There are 8 registers, where register 0 is always 0. It supports 216=65536 words of memory (so there are only that many possible instructions and total pieces of memory).\nLC2K ISA\n(Copied and Pasted from the P1 Spec)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAssembly language name for instructionInstruction Opcode in binaryActionadd  (R-type instruction)0b000Add contents of regA with contents of regB, store results in destReg.nor  (R-type instruction)0b001Nor contents of regA with contents of regB, store results in destReg. This is a bitwise nor; each bit is treated independently.lw  (I-type instruction)0b010”Load Word”; Load regB from memory. Memory address is formed by adding offsetField with the contents of regA. Behavior is defined only for memory addresses in the range [0, 65535].sw  (I-type instruction)0b011”Store Word”; Store regB into memory. Memory address is formed by adding offsetField with the contents of regA. Behavior is defined only for memory addresses in the range [0, 65535].beq  (I-type instruction)0b100”Branch if equal” If the contents of regA and regB are the same, then branch to the address PC+1+offsetField, where PC is the address of this beq instruction.jalr  (J-type instruction)0b101”Jump and Link Registerç; First store the value PC+1 into regB, where PC is the address where this jalr instruction is defined. Then branch (set PC) to the address contained in regA. Note that this implies if regA and regBrefer to the same register, the net effect will be jumping to PC+1.halt  (O-type instruction)0b110Increment the PC (as with all instructions), then halt the machine (let the simulator notice that the machine halted).noop  (O-type instruction)0b111”No Operation (pronounced no op)” Do nothing.Note: above, PC refers to the Program Counter; and regA, regB, and destReg refer to Registers\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruction TypeInstructions in categoryDescription of required fieldsR-Type Instructionsadd, noropcode, field0, field1, and field2 are required fields:  field0 is a register (regA)  field1 is a register (regB)  field2 is a register (destReg)I-Type instructionslw, sw, beqopcode , field0 , field1 and field2 are required fields:  field0 is a register (regA)  field1 is a register (regB)  field2 is either a numeric address, or a symbolic address (represented by a label)J-Type instructionsjalropcode, field0, and field1 are required fields:  field0 is a register (regA)  field1 is a register (regB)O-Type instructionsnoop, haltOnly the opcode field is required\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstruction TypeBinary RepresentationR-type instructions (add, nor)bits 24-22: opcode  bits 21-19: reg A  bits 18-16: reg B  bits 15-3: unused (should all be 0)  bits 2-0: destRegI-type instructions (lw, sw, beq)bits 24-22: opcode  bits 21-19: reg A  bits 18-16: reg B  bits 15-0: offsetField (a 16-bit, 2’s complement number with a range of -32768 to 32767)J-type instructions (jalr)bits 24-22: opcode  bits 21-19: reg A  bits 18-16: reg B  bits 15-0: unused (should all be 0)O-type instructions (halt, noop)bits 24-22: opcode  bits 21-0: unused (should all be 0)\nThe offsetField above is a Two’s Complement Number\nLabels\nLabels make assembly code easier to read and write. They let us assign labels to instructions / data (memory locations) and then use them instead of absolute memory addresses (in beq instructions, lw/sw instructions)."},"LEGv8":{"title":"LEGv8","links":["classes/EECS-370","LC2K"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nLEGv8 is a subset of the ARMv8 ISA. It is simplified to make it easier to learn and understand in a classroom environment.\nIt has 32 registers (X0-X31) and 64 bits in each register.\nSome registers have special uses: X31 is always 0 (also called XZR)\nLEG is byte addressable\nARM Instruction Set\n\nArithmetic\n\nAdd\nSubtract\n\n\nData Transfer\n\nLoads and Stores—LDUR (load unscaled register), STUR, etc\n\n\nLogical\n\nAND, ORR, EOR, etc.\nLogical Shifts (LSL, LSR)\n\n\nConditional Branch\n\nCBZ, CBNZ, B.cond\n\n\nUnconditional Branch (jumps)\n\nB, BR, BL\n\n\n\nArithmetic Instructions (R Instructions)\nFormat: 3 Operand Fields\n\nDestination Register is the FIRST ONE\nADD X3, X4, X7 // X3 = X4 + X7\n\nEncoding given R[Rd] = R[Rn] + R[Rm] (in the add case):\n\nopcode: 11 bits\nRm: 5 bits\nshamt: 6 bits\nRn: 5 bits\nRd: 5 bits\n\nLEGv8 Logical Instructions\n\nLogical operations are bit-wise\nFor immediate fields, the 12 bit constant is padded with zeros to the left\n\nLEGv8 Shift Logical Instructions\nPseudo-Instructions\n\nInstructions that use a shorthand “mnemonic” that expands to pre-existing assembly instructions\nExamples:\n\nMOV X12, X2 // copy X2 into X12 ⇒ ORR X12, XZR, X2\nMOVZ X12, #23 // set X12 to be 23 ⇒ ORRI X12, XZR, #23\n\n\n\nMemory Instructions\nUnlike LC2KISAs]]) is byte addressable. Recall that a word is four bytes.\nJust like LC2K, ARM uses a base + displacement mode. However, in ARM, you can transfer different sizes (instead of the whole 64 bit value). This way, it lets us deal with non-64 bit values.\nLoads\nWhen we’re loading smaller elements from memory, there are two options on what to do with the other bits:\n\nSet them to zero, or zero-extend\nSign-extend (extend based on the most significant bit)\nARM has different instructions for each option so the processor knows what to do.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDesired amount of data to transferOperationUnused bits in register64-bits (double word, or whole register)LDURN/A16-bits (half-word) into the lower bits of registerLDURHSet to zero8-bits (byte) into lower bits of registerLDURBSet to zero32-bits (word) into lower bits of registerLDURSW (load signed word)Sign extend (0 or 1 based on the most significant bit)\nStores\nFor stores, signedness doesn’t actually matter: you’re storing exactly what you said, there’s no extension necessary (or even relevant).\nSequencing Instructions (Control Flow Instructions)\nSequencing Instructions change the flow of instructions that are executed. This is achieved by modifying the program counter (PC).\nConditional Instructions\nType 1: Compare to Zero\nThe first type of Conditional Instruction is comparing to zero, and then branching. This includes CBZ and CBNZ.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstructionExampleWhat it doesCBZCBZ X1, 25If the value in the specified register equals zero, then adjust the program counter by that many lines (multiply by four to get number of bytes)CBNZCBNZ X1, 25If the value in the specified register does not equal zero, then adjust the PC…\nType 2: Program Status Register (non-zero equality comparisons)\nSometimes, you want to do comparisons that are not just equal to zero. For example, a &gt; b, or a = b where b is a variable, etc. ARM allows us to this with with flags.\nThe flags used in ARM for this are NZVC, or Negative, Zero, oVerflow, and Carry. If you run an instruction that also sets a flag, this can then be referenced in a subsequent branch instruction (reference ADDS, SUBS, anything that ends in S).\nFor EECS 370, we’ll focus on N and Z.\nWhile you can use arithmetic operations to set flags (which can save on lines of assembly), the most common way to set a flag is to use the CMP pseudo-instruction. This updates all the flags to allow you to use the correct type of branching.\nC to Assembly\nWhen converting C code to LEG code, there are few important things that you need to keep in mind:\n\nAt least for EECS 370, exams will include doing operations on values that a certain size, and then storing them into items of another size. Being careful about the sizes is important\n\nExample Conversion 1\nC Code:\nstruct {int a; unsigned char b, c; } y;\ny.a = y.b + y.c; // NOTE: a is an integer (32 bits), while b and c are bytes (4 bits)\nAssembly\n/* Assume that a pointer to y is in X1 */\nLDURB X2, [X1, #4] ; it starts 4 bytes after the start of the struct\nLDURB X3, [X1, #5]\nADD X4, X2, X3\nSTURW X4, [X1, #0] ; STURW stores four bytes, or a single word\nMemory Alignment\nWhen dealing with a variables in C or C++, we often need to include padding between data members to make sure things are properly aligned (to help modern hardware access things quickly and efficiently).\nThis means that, even though a struct looks like it only is using, say, 7 bytes of data, it might under the hood actually be using 12 bytes because of alignment.\nModern ISAs enforce the following requirement: an n-byte variable must start at an address A such that Amodn=0. This is called the “Golden Rule of Alignment”\nMemory Alignment Example\nSay we have the following C Code:\nchar   c;\nshort  s;\nint    i;\nThe following memory layout would be created\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0x10000x10010x10020x10030x10040x10050x10060x1007[c]PADDING[s][s][i][i][i][i]\nSo this ends up being eight bytes long. If the compiler can not change the order of fields, and the short and int declarations were swapped, this same “structure” would take 10 bytes of memory instead.\nAligning Arrays\nWe treat arrays like they’re just multiple of the original type, and align the start of the array accordingly.\nAligning Structs\nStructs start to break things. Specifically, in the case where you have an array of structs. Following the above procedure, we’d end up with different padding gaps between different structs, which makes it very difficult (if not impossible) to be able to navigate within the array.\nThis requires an addition to the golden rule: identify the largest primitive field, and ensure that the starting address of the overall struct is aligned based on that largest field (and add padding to the back so that the total size is a multiple of the largest primitive).\nExample Conversion 2: Branching\nC Code\nint x, y; // assume x is in X1, y is in X2\nif (x == y)\n\tx++;\nelse\n\ty++;\nAssembly Code\n\tCMP X1, X2\n\tB.EQ if\nelse:\n\tADD X2, X2, #1\n\tB end ; unconditionally branch to end\nif:\n\tADD X1, X1, #1 ; the # symbol makes it so that you don&#039;t need to specify ADDI\nend:\nAlso Valid Assembly Code\n\tCMP X1, X2\n\tB.NEQ else\nif:\n\tADD X1, X1, #1\n\tB end\nelse:\n\tADD X2, X2, #1\nend:\nExample Conversion 3: Loops\nC Code\n// assume all vraibles are long lon integers (8 bytes, 64 bits)\n// i is in X1, start of a is at address 100, and sum is in X2\nsum = 0;\nfor (i = 0; i &lt; 10; i++) {\n\tif (a[i] &gt;= 0) {\n\t\tsum += a[i];\n\t}\n}\nAssembly Code:\n\tMOVZ X2, #0 ; set sum to zero\n\tMOVZ X1, #0\nstart:\n\tCMPI X1, #10 ; compare i to 10\n\tB.GE end\n\tLSL X3, X1, #3 ; we need to increment by eight bytes\n\tLDUR X3, [X3, #100] ; load the current value of a[i]\n\tCMPI X3, #0\n\tB.LT elseif ; if it&#039;s not geq 0, then continue\n\tADD X2, X2, X3 ; add value to sum\nelseif:\n\tADD X1, X1, #1 ; increment i\n\tB start ; start from start\nend:\nFunction Calls\nSometimes, function calls can be very far away: more than the 219 instructions that a typical CBZ or CBNZ branching instruction might take. This is where unconditional branching comes into play, to let us unconditionally go to far locations.\nSince unconditional branches are, well, unconditional, no other registers need to be specified, so they allow us to specify an address up to 26 bits away, which is more than 64 million instructions. This should be plenty.\nThere are three types of unconditional branches in the LEGv8 ISA:\n\nBranch: B\n\nSyntax: B #OFFSET → go to PC + 4 * OFFSET (byte addressable)\n\n\nBranch to Register: BR\n\nSyntax: BR X30 (or any other register) → go to the address stored in that register\n\n\nBranch with link: BL\n\nThis is commonly used in function calls\nBL #OFFSET → Store PC + 4 into X30 and go to PC + 4 * OFFSET\n\n\n\nThe Call Stack\nIn many situations, functions might be “passed in” data that is more than can fit in however many registers can be used to get data passed in. There needs to be a temporary place to store these values when they get passed to the function: the solution is the calls stack.\nThink of the call stack as a stack of scratch paper: you can add more on top and use it and scribble things on top of it, but it is really all just temporary. When you’re done with a piece of paper, you can throw it out, shred it, and eliminate any trace that it was actually there.\nEvery time we call a function, a stack frame is allocated for that function, and then discarded when that function is complete."},"Linking":{"title":"Linking","links":["classes/EECS-370","LC2K","Object-Files"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nWhen linking LC2K Object Files, there are a few situations you can encounter.\nWhat to Link\nLinking simply involves a) checking global labels and b) making any modifications necessary as marked by the Relocation Table.\nThere are four types of values that your relocation table can link: Text → Text, Data → Text, Text → Data, and Data → Data.\nLinking to Text\nWhen you’re linking to something in the Text Section, the process followed is simple:\n\nSince all text is grouped together, calculate how many lines from the beginning were added before the file that you’re linking too. Then, add the value from the symbol table to this calculation (if relevant)\nAdd this calculated value to the “immediate” value of the instruction.\n\nLinking to Data\nWhen you’re linking from to something in Data, the process is also fairly simple, but has a few caveats.\n\nSince data comes after all text, take the total number of lines from the beginning that were added before the data section that you were referring to.\nHere is the caveat: if the label is a global label, add the symbol table offset to this line number and set the “immediate” to this newly calculated value.\nIf it is local, we can simply add the additional lines offset to our sw/lw functions (and the offset from the data section should already be accounted for).\n\nYou just need to subtract the number of lines in the text section of the relevant file to avoid double counting.\n\n\n"},"Number-Bases":{"title":"Number Bases","links":["classes/EECS-370","classes/EECS-376"],"tags":["eecs-370"],"content":"Related Classes: EECS 370, EECS 376\nThink of any number, n. You might be thinking of seventeen, or twenty-five, or even sixty-nine. But what does this number represent? All it is fundamentally representing is a quantity, an amount of something.\nThis quantity can be written, or displayed, in many ways. These different portrayals are called Bases.\nDecimal\nThe most commonly used number base is Base-10, more commonly referred to as decimal. We have ten fingers, ten toes, and we have ten different digits to represent numbers: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. And that’s what decimal is all about: we can use these ten different digits to represent any quantity: seventeen is 17, twenty-five is 25, and sixty-nine is 69.\nBinary\nThe second most commonly seen number base is Base-2, or binary. This is what all modern standard computers are built off of, or based on. Here, we only use the digits 1, 0 to represent any number. seventeen would be 10001, twenty-five would be 11001, and sixty-nine is 1000101.\nHexadecimal\nOctal"},"Object-Files":{"title":"Object Files","links":["classes/EECS-370","LC2K","Linking"],"tags":["eecs-370"],"content":"Related Courses: EECS 370\nObject files are an intermediary between assembly and machine code that allows you to split up code into multiple files. It essentially allows you to declare a label in one file and use it in another, and have the assembler and linker handle the rest of the process of connecting these defragmented pieces.\nWhat’s in an Object File\nSince an object file contains everything we’ll need to be able to turn it into machine code, there are a few required sections that are able to describe everything in the program.\nWe’ll describe these using LC2K, but the concept is the same regardless.\nHeader\nThe header is a very simple part of the object file that describes the size each section within the rest of the file.\nLC2K Example\n5 4 3 2\n\nThe above header section is saying that theres five lines of text (instructions) in our object file, four lines of data, three items in the symbol table, and two items in the relocation table.\nText\nThis includes all the machine code you were able to generate—with some defaults for undefined labels.\nData\nThis includes all globals, static locals, and all the data that .fill directive is used to describe. Usually, this does not include uninitialized data values, but for LC2K we use the simplifying assumption that all data will go here.\nSymbol Table\nThis is going to list all the labels (and all of the function names and variable names) that are visible outside this file. All globals will be listed here, and depending on who you ask, static variables would also go here.\nRelocation Table\nThis is the list of all instructions and data declarations that are going to have to be updated at during Linking (because things will move around in memory)."},"Pipelining":{"title":"Pipelining","links":["classes/EECS-370","LC2K-Single-Cycle-Datapath","LC2K-Multi-Cycle-Datapath","Parallelism","Combinational-Logic","Branch-Prediction","Instruction-Set-Architecture-(ISA)","Program-Counter"],"tags":["eecs-370"],"content":"Relevant Classes: EECS 370\nWhen considering a Single-Cycle ProcessorMulti-Cycle Processor]] has a higher CPI, but a lower clock period. With Pipelining, we hope to take the best of both worlds: approach a CPI of 1 while being able to keep a lower clock period.\nYou might notice that in a Multi-Cycle Processor, a lot of the hardware is being unused at a certain time: the idea behind pipelining is to use this unused hardware to start working on future instructions at the same time as current ones. This concept is referred to as Parallelism.\nA great analogy to pipelining are Drive-Thrus…\nThe Datapath\n\nThe biggest change is the introduction of pipeline registers: these preserve / store the previous values of a certain pipeline step to allow moving from one step to the next without having the next instruction modify data that is being used.\nOther Minor Changes:\n\nIntroducing More AddersALUs]] again (like in Single-Cycle) since they’ll be used at the same time\nReversing the von Neumann Architecture again (splitting up Data and Instruction Memory)\n\nNote: this will be amended / explained later in the course to make this no longer an issue\n\n\n\nStage 1: Fetch (IF)\n\nFetch the next instruction and store it in the pipeline register\nCalculate PC + 1 and store it in PC (unless you get a different value from beq or jalr)\n\nAlso store PC + 1 in pipeline register\n\n\n\nStage 2: Decode (ID)\n\nRead Register Values and store it in the next pipeline register\nPass forward the instruction bits and PC + 1 to the next pipeline register\n\nStage 3: Execute (EX)\n\nActually use ALU to do operation (add, nor, regA + offset, etc) and store it in the next pipeline register\nAlso calculate PC + 1 + offset in case it is needed and pass it to the next pipeline register\nPass forward the contents of regB and instruction bits to the next pipeline register\n\nStage 4: Memory Operation (Mem)\nNote: this is only used in the case of lw/sw\n\nPotentially use ALU Result as destination for value of regB in the case of sw and pass forward the memory data read (for the case of lw)\nPass forward ALU Result and instruction bits to the next pipeline register\nAt this stage, pass PC + 1 + offset back to the original Fetch Stage\n\nStage 5: Write Back (WB)\nThis is only used for things that need to be written back to register files (lw, add/nor).\n\nBased on the instruction, pass the relevant values back to the Decode Stage where the Register file is stored.\nAlso turn on / off the write enable signal\n\nHazards\nThere are two main types of hazards: Data Hazards and Control Hazards.\nData Hazards: Since register reads happen at Stage 2 and register writes happen at stage 5, it is possible to read an old / stale value before the correct value is written back in.\nControl Hazards: A branch instruction may change the PC, but not until stage 4. What do we fetch before that? (In modern processors, this is where Branch Prediction comes into play).\nData Hazards\nSome preliminary definitions:\nData Dependency: one instruction uses the result of a previous one (not necessarily problematic)\nData Hazard: one instruction has a data dependency that will cause a problem if we don’t properly handle it.\n\nWe can assume that, if you’re reading from a register the same cycle you’re writing to it, the register file is smart enough to give the reader will give you the correct (new) value. This will help us identify data hazards. This is also consistent with most processors (ARM, x86) but not on the next EECS 370 Project.\n\nExample A:\nadd 1 2 3\nnor 3 4 5\nIt is very clear here that the nor has a data dependency on add. However, in our pipeline processor, if we load nor beforehand, it will read the old value in r3 before it is updated by the add instruction, leading to subsequent incorrect calculations.\nThere are three basic solutions to handling data hazards:\n\nAvoid: Make sure there are no hazards in the code (rip programmer).\nDetect and Stall: If hazards exist, stall the processor until they go away.\nDetect and Forward: If hazards exist, fix the pipeline to get the correct value if possible (hardware changes)\n\nAvoidance\nSimply: make sure there are no ha\n”Solution” to Example A:\nadd 1 2 3\nnoop\nnoop\nnor 3 4 5\nClearly, this isn’t that great. Since the ISA doesn’t describe the hardware, each iteration of a processor could have a different number of pipelines, so code will have to be recompiled each time. Furthermore, after compiling, a bunch of noop instructions would be introduced, adding to the executable size. And if that wasn’t enough, it also (clearly) makes the program slower.\nDetect and Stall\nEssentially, do the insertion of noops at the hardware level.\nThis makes sure code doesn’t need to change, but adds a small amount of hardware complexity. This solves the backwards compatibility and executable size issue, but does not fix the speed of the program: CPI is no longer approaching 1 because of all the stalling we’re doing.\nDetect and Forward\nThere are certain values of data that are ready at different stages of the program (e.g. add/nor results are ready after the execute stage). If we can skip the writeback stage during a hazard and forward those results early, we could avoid a lot of excess stalls. Essentially, allow the program to read incorrect values from the register first, and then modify / update them later before they’re used using hardware rerouting.\nThis does not eliminate all stalls, but can greatly reduce the number of stalls needed in a program compared with [[#detect-and-stall|Detect and Stall]].\nThis leads to four different types of hazards, which all require different approaches to solving the hazard. The following assembly should describe these different options:\nadd 1 2 3\nnor 2 3 4 ; hazard &quot;1&quot; \nadd 6 3 7 ; hazard &quot;2&quot;\nlw 3 6 10 ; no hazard\nsw 6 2 12 ; hazard &quot;3&quot;\n\nThese Hazards are not mutually exclusive: regA and regB can both be hazarded, and the hazards can be different. Therefore, the circuit gets quite a bit more complicated.\n\nThe only time a stall is now added is when have an `lw` command directly followed by a dependent instruction (since `lw` requires an additional cycle to read from memory).\nHazard “1”\nIn this case, the value of register 3 should actually come from the result of the previous ALU operation. Therefore, we can use a Mux to decide between using the Register Value and the previous ALU calculation (based on the Hazard State)\nHazard “2”\nIn this case, we still depend on the value of register 3 which is now in the Memory Stage. We add another wire from the forwarded ALU result to the Mux described in Hazard “1” and can use the flag of Hazard “2” to choose the correct value.\nHazard “3”\nThis can’t be solved with forwarding: lw needs to finish accessing data memory before it knows what the new value for the register is supposed to be. In this case, we can stall once so that we can finish reading from memory.\nWe only need to stall once, however, because we can directly link the Writeback StageExecute Stage]] and use a Mux to decide between which value to use.\nControl Hazards\nWhen we’re branching, the Program Counter can potentially change, so we don’t really know what the actual next instructions are going to be.\nJust like with Data Hazards, we have three strategies to handle control hazards.\n\nAvoid: Don’t include beq in code\nDetect and Stall\nSpeculate and Squash-If-Wrong:\n\nGuess outcomes of branch\nFetch instructions assuming we’re right\nStop them if they shouldn’t have been executed (this relies on the Writeback stage stopping any data modification until the end)\n“Branch Prediction” when complex\n\n\n\nBecause Avoid is very self explanatory and similar to what we explained Data Hazards, I won’t add this here.\nDetect and Stall\nDetection:\n\nwait until decode\ncheck if opcode == beq or jalr\n\nStall:\n\nKeep current instructions in fetch\nInsert noops\nPass noop to decode stage, not execute (pass early)\n\nFor each beq, this inserts 3 noop instructions.\nSpeculate and Squash-If-Wrong\nSpeculate: assume they’re not equal\n\nKeep fetching from PC + 1 until we know that the branch is really taken\n\nSquash: stop bad instructions if taken\n\nsend a noop to Decode, Execute, and Memory\n\noverwriting any instruction that might have been there and essentially turning all calculated values into junk\nonly adds the 3 noop instructions in “half” the cases\n\n\nsend target address to PC\n"},"Priority-Queue":{"title":"Priority Queue","links":["classes/EECS-281","Customizable-Containers","Abstract-Data-Type-(ADT)"],"tags":["eecs-281","data-structure"],"content":"Relevant Classes: EECS 281\nIn a Priority Queue (colloquially referred to as a pq), each “datum” is paired with a priority value. For example, it could be the value of the data point itself in a priority queue of numbers. A PQ supports insertion of data, and inspection (which involves “looking” at the datum with highest priority).\nNote: Priority Queues are Customizable Containers. You can change the “comparator” used to determine the priority (min-pq, max-pq, custom-pq).\nAbstract Data Type (ADT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodDescriptionpush(object)Add object to the priority queuepop()Remove element with the highest priorityconst object&amp; top()Return a reference to the highest priority elementsize()Number of elements currently in the priority queueempty()Checks if the priority queue has no elements\nExamples\n\nEmergency Call Centers:\n\nOperators receive calls and assign levels of urgency\nLower numbers indicate more urgent calls\nCalls are dispatched to police squads based on urgency\n\n\nHospital queue for arriving patients\nLoad Balancing for Servers\n\nTime Complexity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsertRemoveUnordered Sequence ContainerConstantLinearSorted Sequence ContainerLinearConstantBinary HeapLogarithmicLogarithmicArray of Linked Lists (for priorities of small integers)ConstantConstant"},"Queue":{"title":"Queue","links":["classes/EECS-281","Abstract-Data-Type-(ADT)","Circular-Buffer","Linked-List"],"tags":["eecs-281","data-structure"],"content":"Relevant Classes: EECS 281\nQueues support insertion / removal in FIFO (first in, first out) order.\nAbstract Data Type (ADT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodDescriptionpush(object)Add object to the back of the queuepop()Remove element at the front of the queueobject&amp; top()Return a reference to the element at the front of the queuesize()Number of elements currently in the queueempty()Checks if the queue has no elements\nExamples\n\nLunch Line\nAdding Songs to a Playlist\n\nImplementations\nContiguous Memory: Circular Buffer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodImplementationTime Complexitypush(object)1. If size == capacity, reallocate larger array and copy over elements, “unrolling” as you go (unroll: start front_idx at 0, insert all elements)2. Insert value at back_idx, incrementing size and back_idx, wrapping around either as neededAmortized O(1), Worst-Case O(n)pop()Increment front_idx, decrement sizeO(1)object&amp; top()Return reference to element at front_idxO(1)size()Return sizeO(1)empty()Check if size == 0O(1)\nConnected Memory: Linked List\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodImplementationTime Complexitypush(object)Append node after tail_ptr, increment sizeO(1)pop()Delete node at head_ptr, decrement sizeO(1)object&amp; top()Dereference head_ptrO(1)size()Return sizeO(1)empty()Return head_ptr == nullptr (or when size == 0)O(1)"},"Read-Only-Memory-(ROM)":{"title":"Read Only Memory (ROM)","links":["classes/EECS-370","Sequential-Logic","Combinational-Logic"],"tags":["eecs-370"],"content":"Relevant Classe: EECS 370\nRead-Only Memory is an “array” of values that are constant and non-volatile. This means that if, for example, the power cuts off, the data is still preserved. Consider the alternative, a D Flip-Flop. The second the power goes out, a D Flip-Flop will lose the current data it is storing: however, a ROM will not.\nYou can think of ROM as a table: you can have n input bits, and thus 2n different output combinations, based on the input bits. Thus, you might notice, that the input is turned into a single bit using a Decoder.\nIn addition, a ROM can have as many “output” bits as you want, and each input combination determines what the output bits are set to. Thus, the size of the ROM can be calculated as follows:\nIf you have $n$ input bits and $y$ output bits, that means that there are $2^n$ possible &quot;output states&quot;, and each output state has $y$ bits that it needs to set. Therefore, the size of a ROM in this configuration is $y \\cdot 2^n$ bits\nThere are two primary types of ROMs.\nProgrammable Read Only Memory\nThis type of ROM only gives you one chance to write to it: once it’s written to, it’s done and can’t be written to again. Generally, these are implemented with diodes and other physical circuitry that, upon writing, is broken—limiting the amount of changes that can be made in the future.\nElectronically Erasable PROM (EEPROM)\nYou can write to memory electronically, but with EEPROMs you can use hardware to reset bits if you need to update the values."},"Registers":{"title":"Registers","links":["classes/EECS-370"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nRegisters are a small number (generally 8-32) of fixed-length hardware variables that have simple names like “r5” or “X31”.\nThey are much faster than accessing memory multiple times and are used to store small amounts of data for instructions."},"Sequential-Logic":{"title":"Sequential Logic","links":["classes/EECS-370","LC2K-Multi-Cycle-Datapath"],"tags":["eecs-370"],"content":"Relevant Classes: EECS 370\nSequential Logic allows us to create circuits that “remember” or have a memory.\nSR Latch\nD Latch\nA D-Latch is a Latch that is connected to a clock that “updates” while the clock is high and “holds” the last value while the clock is low.\nD Flip-Flop\nA D Flip-Flop is used more often and, only when the clock goes from high to low (or low to high, or both, depending on the implementation) does it update the “stored” value to whatever the input value was at that instant. This can lead to unspecified behavior if the value of both the input and the Flip-Flop change at the same time.\nThe benefit, however, is for input-output loops, where the input to the data depends on the previous output for the data (and often some math in between). In the D Latch case, this can lead to a huge amount of loops / cycles, which would cause the value to become unstable (because it keeps changing). Think of the PC + 1 case. You could be adding 1 a ridiculous number of times, because you keep doing it while the clock is high.\nA D Flip-Flop fixes that, because the value is only updated once every clock cycle, so there is no unspecified behavior like above.\nSometimes, a Flip-Flop will have even an enable bit to avoid changing a value until it something else is complete (cough cough LC2K Multi-Cycle Datapath)"},"Stack":{"title":"Stack","links":["classes/EECS-281","Abstract-Data-Type-(ADT)","Vector","Linked-List"],"tags":["eecs-281","data-structure"],"content":"Relevant Classes: EECS 281\nStacks support insertion / removal in LIFO (last in, first out) order.\nAbstract Data Type (ADT)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodDescriptionpush(object)Add object to the top of the stackpop()Remove top elementobject&amp; top()Return a reference to the current top elementsize()Number of elements currently in the Stackempty()Checks if the stack has no elements\nExamples\n\nWeb browser’s “back” feature\nText editor’s “Undo” feature\nFunction calls in C++\n\nImplementations\nContiguous Memory: Vector\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodImplementationTime Complexitypush(object)1. If needed, allocate a bigger array and copy data2. Add a new element at top_ptr, increment top_ptrAmortized O(1), Worst-Case O(n)pop()Decrement top_ptrO(1)object&amp; top()Dereference top_ptr - 1O(1)size()Substract base_ptr from top_ptr pointerO(1)empty()Check if base_ptr == top_ptrO(1)\nConnected Memory: Linked List\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMethodImplementationTime Complexitypush(object)Insert a new node at head_ptr, increment sizeO(1)pop()Delete node at head_ptr, decrement sizeO(1)object&amp; top()Dereference head_ptrO(1)size()Return sizeO(1)empty()Check if size == 0 or head_ptr == nullptrO(1)"},"Trends-in-Computing":{"title":"Trends in Computing","links":["classes/EECS-370"],"tags":["eecs-370"],"content":"Related Classe: EECS 370\nMoore’s Law\nThe number of transistors on a single microchip doubles every two years.\nThis is usually accomplished by making transistors smaller. However, we have already reached a point where transistors are sized at the scale of atoms. Clearly, a single transistor can not be smaller than an atom, so there will come a point soon where we physically can’t make transistors any smaller.\nDennard Scaling\nAs transistors get smaller, their power density stays constant.\nThis is saying that, when given a certain area of microchip, the power consumed in that same area remained roughly the same as the number of processors on the chip increased.\nHowever, in the Mid-2000s, this trend ended. This is because of Quantum Leaping, which leads to power leaking and excess power consumption."},"Two's-Complement-Numbers":{"title":"Two's Complement Numbers","links":["classes/EECS-370"],"tags":["eecs-370"],"content":"Related Classes: EECS 370\nThis is the most commonly used methodology to represent signed integers in binary. Recall that in binary, the i-th digit from the right represents 2i, where i starts at 0. Consider the following number: 0b1101=1⋅23+1⋅22+0⋅21+0⋅20=8+4+1=13.\nTwo’s Complement numbers are very similar: the only difference is that the most significant bit is now negative. Considering the same example, the number 0b1101 in two’s compliment is: 0b1101=1⋅(−23)+1⋅22+0⋅21+0⋅20=−8+4+1=−3.\nIf you want to negate a number, it’s very simple in two’s complement: flip every bit (or nor a number with itself or 0) and then add 1.\nSo, to get the -3 above, we’d start with a binary 3: 0b0011. Then, we’d flip all the bits to get 0b1100. Finally, we’d add 1 to get 0b1101, which is the same as above.\nAs you might be able to tell, the range of an n-bit two’s complement number is: [−2n−1,2n−1−1] (inclusive)."},"cheatsheets/EECS-281-Midterm-Cheat-Sheet":{"title":"EECS 281 Midterm Cheat Sheet","links":["The-Master-Theorem","Elementary-Sorts","Iterators","The-Standard-Template-Library"],"tags":["eecs-281","cheatsheet"],"content":"Equations / Charts to Include\n\nThe Master Theorem\nSorting Algorithm Comparisons\n\nStable vs Unstable\nRuntime\nBest Case\nWorst Case\n\n\nIterators\nSTL Functions\n\n"},"cheatsheets/EECS-370-Midterm-Cheatsheet":{"title":"EECS 370 Midterm Cheatsheet","links":["LEGv8","LC2K","Combinational-Logic","Floating-Point-Numbers","LC2K-Single-Cycle-Datapath","LC2K-Multi-Cycle-Datapath","Pipelining"],"tags":["eecs-370","cheatsheet"],"content":"Things to Include\n\nCommon LEGv8 Operations\nLC2K Opcodes\n\nLC2K Instruction Encodings\n\n\nLogic Gates\nPowers of Two\nFloating Point Numbers\nSingle-Cycle Datapath (screenshot?)\nMulti-Cycle Datapath (screenshot?)\n\nNumber of Cycles per instruction\n\n\nThe Datapath (screenshot?)\nMetric Prefixes\n"},"classes/EECS-203":{"title":"Discrete Math","links":[],"tags":["eecs-203"],"content":""},"classes/EECS-280":{"title":"Programming and Data Structures","links":[],"tags":["eecs-280"],"content":""},"classes/EECS-281":{"title":"Data Structures and Algorithms","links":[],"tags":["eecs-281"],"content":""},"classes/EECS-370":{"title":"Introduction to Computer Organization","links":["exams/EECS-370-Midterm","cheatsheets/EECS-370-Midterm-Cheatsheet"],"tags":["eecs-370"],"content":"Exam Guides\n\nMidterm Exam: EECS 370 Midterm\n\nCheatsheet Content: EECS 370 Midterm Cheatsheet\n\n\n\nSchedule of Topics\nTBD"},"classes/EECS-376":{"title":"Foundations of Computer Science","links":[],"tags":["eecs-376"],"content":""},"classes/EECS-482":{"title":"Introduction to Operating Systems","links":[],"tags":["eecs-482"],"content":""},"exams/EECS-281-Midterm":{"title":"EECS 281 Midterm","links":["classes/EECS-281","Stack","Complexity-Analysis","Substitution-Method-(Time-Complexity)","Big-O-Notation","Recursion","The-Master-Theorem","Array","Linked-List","Iterators","Heaps","Heapsort","Elementary-Sorts","Quicksort","Mergesort"],"tags":["eecs-281","content-summary"],"content":"Relevant Class: EECS 281\nTopics Covered\n\nStackADTs]]\nComplexity Analysis (Substitution Method (Time Complexity), Big-O Notation)\nRecursion (and The Master Theorem)\nContainer Data Structures (ArrayVector]], Linked List)\n\nIterators\n\n\nHeaps and Heapsort\nOrdered Arrays and Related Algorithms\nSorting\n\nElementary SortsBubble Sort]]Selection Sort]])\n\nSort Adaptations / Improvements\n\n\nQuicksort\nMergesort\n\n\n"},"exams/EECS-370-Midterm":{"title":"EECS 370 Midterm","links":["classes/EECS-370","Trends-in-Computing","Assembly","Instruction-Set-Architecture-(ISA)","LC2K","LEGv8","Number-Bases","Two's-Complement-Numbers","Floating-Point-Numbers","Endianness","Caller-Save-vs-Callee-Save","Object-Files","Combinational-Logic","Sequential-Logic","Finite-State-Machine-(FSM)","Read-Only-Memory-(ROM)","LC2K-Single-Cycle-Datapath","LC2K-Multi-Cycle-Datapath","Pipelining"],"tags":["eecs-370","content-summary"],"content":"Relevant Class: EECS 370\nTopics Covered\nI’m going to be very honest, I have no idea what’s actually going to be on this exam (specifically, how much of data hazards / control hazards and beyond are going to be on the exam). But here’s my best guess:\n\nTrends in Computing\n\nMoore’s Law\nDennard Scaling\n\n\nAssembly:\n\nInstruction Set Architecture (ISA)\nLC2K\nLEGv8\n\n\nRepresenting Data:\n\nBinary, Hex, Octal, Decimal\nTwo’s Complement Numbers\nFloating Point Numbers\nEndianness\n\n\nAssembling LC2K into Machine Code\nC to Assembly (Specifically LEGv8)\nStruct Alignment\nFunction Calls\n\nCaller Save vs Callee Save\nAssigning Variables to Memory Locations\n\n\nObject Files\n\nSymbol Table\nRelocation Table\n\n\nCombinational Logic\n\nLogic Gates\nMuxes\nDecoders\nALUs\nPropagation Delay\n\n\nSequential Logic\n\nSR Latch\nD Latch\nD Flip-Flop\n\n\nFinite State Machine (FSM)\n\nRead Only Memory (ROM)\nMoore MachinesMealy Machines]]\n\n\nSingle-Cycle Processor\n\nLC2K Single-Cycle Datapath\n\n\nMulti-Cycle Processor\n\nLC2K Multi-Cycle Datapath\n\n\nPipelining\n"},"ia-applications/EECS-203-IA-Application-Video-Plan":{"title":"EECS 203 IA Application Video Plan","links":[],"tags":["eecs-203"],"content":"Topic: Combinations &amp; Permutations"},"ia-applications/EECS-281-IA-Application-Video-Plan":{"title":"EECS 281 IA Application Video Plan","links":[],"tags":["eecs-281"],"content":"Topic: Disjoint Set Union and Union-Find\n\nFavorite Algorithm / Data Structure\nExample: we have this random graph and we want to know if a vertex v is connected to another vertex w\n\nweb of “connections” of students in the University of Michigan\nis it possible to get from person v to person w through mutual connections?\n\n\nHow many connected components are there?\nNaive Approach: DFS/BFS Each Time\n\nFor each vertex, we’ll need to search through all its children to see if we can find w\n\n\n\nSolution: DSU\n\nThe inspiration is thinking about sets\nTwo operations\n\nunion(x, y)\nfind(x)\n\n\nFor this approach, think of a leadership structure\n\nHow do you find out if two citizens are from the same country? Check if they have the same leader\n\n\nWorst Case: O(n) (but with path compression, it becomes amortized O(α(n)).\n"},"index":{"title":"Welcome to my Course Notes","links":[],"tags":[],"content":"This is just a collection of notes I’ve taken of courses I’ve taken at the University of Michigan, with no rhyme or reason. Maybe I’ll actually organize them at some point ¯_(ツ)_/¯"}}